### 正確な直線探索
$\phi(\alpha) := f(\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k)$

- $ \underset{\alpha > 0}{\min} \phi(\alpha) = 
    \underset{\alpha > 0}{\min} f(\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k) \\\\
    \alpha\_k \in \underset{\alpha > 0} {\text{arg}\min}
    \lbrace f(\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k) \rbrace \\\\
    \text{e.g.} \alpha\_k = \min \lbrace \alpha \mid f(\boldsymbol{x} + \alpha \boldsymbol{d}\_k) = 
    \underset{\alpha > 0} {\min} f(\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k) \rbrace$

- $\underset{\alpha > 0}{\min} \phi(\alpha)$ となる$\alpha$の一時の必要条件
  - $\phi^\prime (\alpha) = 0$ ($\alpha$の非線形方程式)
  - i.e. $
    \phi^\prime(\alpha) = \nabla f (\boldsymbol{x} + \alpha \boldsymbol{d}\_k)^T \boldsymbol{d}\_k = 0 \\\\
    \alpha\_k \in \lbrace \alpha \mid
    \nabla f (\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k)^T \boldsymbol{d}\_k = 0 \\\\
    \text{e.g.} \alpha\_k =
    \min \lbrace \alpha \mid \nabla f (\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k)^T \boldsymbol{d}\_k = 0,
    \alpha > 0 \rbrace$


これらの正確な直線探索は次のような欠点を持つ

- 有限回の手順で$\alpha\_k$を求められない(一般に無限回の手順が必要)
  - ($\Rightarrow$ 効率的/実用的ではない)


### 不正確な(非厳密な)直線探索
- 有限回の手順で終了
- Armijo's LS
  - $0 < \epsilon < 1$,定数 $\boldsymbol{d}\_k$:$f$の降下方向
    (i.e. $ \nabla f(\boldsymbol{x}\_k)^T \boldsymbol{d}\_k < 0 $)
  - $f (\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k) \leq
    f(\boldsymbol{x}\_k) + \xi \alpha \nabla f(\boldsymbol{x}\_k)^T \boldsymbol{d}\_k \ \cdots (\ast)$
    となる$\alpha > 0$を選ぶ
  - $\alpha \fallingdotseq 0$のとき
    - $f (\boldsymbol{x}\_k + \alpha \boldsymbol{d}\_k) \simeq
      f(\boldsymbol{x})\_k + \alpha \nabla f(\boldsymbol{x}_k)^ T\boldsymbol{d}\_k$
     ($\alpha \nabla f(\boldsymbol{x}_k)^ T\boldsymbol{d}\_k < 0$)
    - [$\phi (\alpha) \simeq \phi(0) + \phi^\prime (0) \alpha$]
      - ($\phi^\prime (0) \alpha < 0$)
      - よって$\alpha > 0, \alpha \fallingdotseq 0$のとき、$(\ast)$を満たす

Wolfe's LS

もよく使われる(省略)

Armijo's LS を実現する一つの方法として、Backtracking Method

### Backtracking Method
#### Step 0
- Given
  - $\boldsymbol{x}\_k$: 近似点
  - $\boldsymbol{d}\_k$: 探索方向
  - $\xi \in (0, 1)$: Armijoパラメータ(e.g. $0.01 = 10^{-2} \sim 10^{-4}$)
  - $\tau \in (0,1$: 縮小率 (e.g. $\tau = 0.5 = \frac{1}{2}$)
  - $\beta\_0 > 0$: 初期ステップ幅(e.g. \beta\_0 = 1)

$\beta := \beta\_0, i := 0$とおく

#### Step 1
$f(\boldsymbol{x}\_k + \beta\boldsymbol{d}\_K) - f\_k \leq \xi \boldsymbol{g}\_k^T \boldsymbol{d}\_k$
$\Rightarrow$ Step 3へ

ただし、$f\_k := f(\boldsymbol{x}\_k
, \boldsymbol{g}\_k := \boldsymbol{g}(\boldsymbol{x}\_k) =\nabla f(\boldsymbol{x}\_k)$

#### Step 2 (バックトラック)
$\beta := \tau \beta, i := i + 1$とおき、Step 1へ戻る

#### Step 3
$\alpha\_k = \beta$を採用して終了(内部反復$i$回)

特に$\tau = 0.5 = \frac{1}{2}$にとれば2分法になる

## 4.5 最急降下法
$\boldsymbol{d}\_k$の決め方

- 最急降下法(steepest descent method : SD法)
  - 1次モデル $f(\boldsymbol{x}\_k + \boldsymbol{d}) \simeq l\_k(\boldsymbol{d}) =
    f(\boldsymbol{x}\_k) + \nabla f(\boldsymbol{x}\_k)^T \boldsymbol{d}$
    を局所的に最小にする方向は？


$\min \nabla f(\boldsymbol{x}\_k)^T \boldsymbol{d} (\nabla f(\boldsymbol{x}) \neq \boldsymbol{0})$

$\text{s.t.} \parallel \boldsymbol{d} \parallel = \parallel \nabla f(\boldsymbol{x}\_k) \parallel$

$\nabla f\_k$と$\boldsymbol{d}$とのなす角を$\theta (0 \leq \theta \leq \pi)$とすると

$\nabla f\_k^T \boldsymbol{d} =
 \parallel \nabla f\_k \parallel \parallel \boldsymbol{d} \parallel \cos \theta \geq
 \parallel \nabla f\_k \parallel^2 (-1)$

$\boldsymbol{d} = -\nabla f\_k$ [これがSD方向]

のとき$\nabla f\_k^T\boldsymbol{d}$が最小

$\boldsymbol{d}\_k := - \nabla f\_k = - g\_k$は降下方向

$\boldsymbol{d}\_k^T \nabla f\_k = - \parallel \nabla f\_k \parallel^2 = - \parallel g\_k \parallel^2 < 0$


## Newton 法
2次モデル
$f(\boldsymbol{x}\_k + \boldsymbol{d}) \simeq q\_k(\boldsymbol{d}) ;=
f(\boldsymbol{x}\_k) + \nabla f(\boldsymbol{x}\_k)^T \boldsymbol{d} +
\frac{1}{2} \boldsymbol{d}^T \nabla^2 f(\boldsymbol{x}\_k) \boldsymbol{d}$

を局所的に最小化する方向は？

$\underset{\boldsymbol{d} \in \boldsymbol{R}}{\min} q\_k (\boldsymbol{d}$

必要条件として

$\nabla q\_k(\boldsymbol{d}) = \boldsymbol{0} \Leftrightarrow
\nabla f(\boldsymbol{x}\_k) + \nabla^2 f(\boldsymbol{x}\_k) \boldsymbol{d} = \boldsymbol{0} \Leftrightarrow
\nabla^2 f(\boldsymbol{x}\_k)\boldsymbol{d} = - \nabla f(\boldsymbol{x}\_k)$ (Newton方程式)

この回$\boldsymbol{d} = \boldsymbol{d}\_k$とする。

もし$\nabla^2 f(\boldsymbol{x}\_k)$が正則ならば

$\boldsymbol{d}\_k = - \nabla^2 f(\boldsymbol{x}\_k)^{-1}\boldsymbol{d}\_k = 
\nabla f\_k^T(- \nabla^2 f\_k^{-1} \nabla f\_k) = - g\_k^T\nabla^2f\_k^{-1}\boldsymbol{g}\_k < 0$

$\nabla^2 f\_k$が$\text{p.d.}$でなくても$\boldsymbol{d}\_k$が降下方向になることはある
